import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.Column;
import org.apache.spark.sql.functions;
import org.apache.spark.sql.types.*;
import org.apache.spark.sql.SparkSession;

import java.util.Currency;
import java.util.EnumSet;

public class DatasetFieldProcessor {

    public static Dataset<Row> processDataset(
        SparkSession spark,
        Dataset<Row> dataset,
        int precision,
        int scale,
        String currencyCodeField,
        Enum<?>[] fieldEnum) {

        // Register the UDF for currency fraction digits if not already done
        registerCurrencyFractionDigitsUDF(spark);

        StructType schema = dataset.schema();
        Column extractedCurrencyCode = functions.col("header." + currencyCodeField);

        for (StructField field : schema.fields()) {
            String fieldName = field.name();
            DataType fieldType = field.dataType();

            // Check if the field exists in the enum with or without the prefix "F_"
            String fieldNameWithoutPrefix = fieldName.startsWith("F_") ? fieldName.substring(2) : fieldName;
            boolean isFieldInEnum = false;
            for (Enum<?> enumField : fieldEnum) {
                if (enumField.name().equalsIgnoreCase(fieldNameWithoutPrefix)) {
                    isFieldInEnum = true;
                    break;
                }
            }

            if (isFieldInEnum && fieldType.equals(DataTypes.DoubleType)) {
                // Transform DoubleType fields if they match the enum and are of type Double
                dataset = dataset.withColumn(
                    fieldName,
                    transformDoubleField(functions.col(fieldName), precision, scale, extractedCurrencyCode)
                );
            } else if (fieldType instanceof StructType) {
                // Recursively transform StructType fields
                dataset = dataset.withColumn(
                    fieldName,
                    transformNestedStruct(functions.col(fieldName), (StructType) fieldType, precision, scale, extractedCurrencyCode)
                );
            } else if (fieldType instanceof ArrayType) {
                // Transform ArrayType fields
                dataset = dataset.withColumn(
                    fieldName,
                    transformArrayField(functions.col(fieldName), (ArrayType) fieldType, precision, scale, extractedCurrencyCode)
                );
            }
        }

        return dataset;
    }

    private static void registerCurrencyFractionDigitsUDF(SparkSession spark) {
        // Register the UDF to return the number of fraction digits for a given currency code
        spark.udf().register("currencyFractionDigits", (String currencyCode) -> {
            if (currencyCode == null || currencyCode.isEmpty()) {
                return 2; // Default to 2 decimal places if the currency code is invalid
            }
            try {
                Currency currency = Currency.getInstance(currencyCode);
                return currency.getDefaultFractionDigits();
            } catch (IllegalArgumentException e) {
                return 2; // Default to 2 decimal places for unknown currencies
            }
        }, org.apache.spark.sql.types.DataTypes.IntegerType);
    }

    private static Column transformDoubleField(Column column, int precision, int scale, Column currencyCodeColumn) {
        // Use the UDF to get the number of fraction digits based on the currency code
        Column fractionDigits = functions.callUDF("currencyFractionDigits", currencyCodeColumn);

        // Transform the column to BigDecimal with specified precision and scale
        return functions.expr(
            "CAST(round(" + column + ", " + fractionDigits + ") AS DECIMAL(" + precision + ", " + scale + "))"
        );
    }

    private static Column transformNestedStruct(
        Column column, StructType structType, int precision, int scale, Column currencyCodeColumn) {

        Column[] transformedFields = new Column[structType.fields().length];

        for (int i = 0; i < structType.fields().length; i++) {
            StructField field = structType.fields()[i];
            String fieldName = field.name();
            DataType fieldType = field.dataType();

            if (fieldType.equals(DataTypes.DoubleType)) {
                transformedFields[i] = transformDoubleField(column.getField(fieldName), precision, scale, currencyCodeColumn).alias(fieldName);
            } else if (fieldType instanceof StructType) {
                transformedFields[i] = transformNestedStruct(column.getField(fieldName), (StructType) fieldType, precision, scale, currencyCodeColumn).alias(fieldName);
            } else if (fieldType instanceof ArrayType) {
                transformedFields[i] = transformArrayField(column.getField(fieldName), (ArrayType) fieldType, precision, scale, currencyCodeColumn).alias(fieldName);
            } else {
                transformedFields[i] = column.getField(fieldName);
            }
        }

        return functions.struct(transformedFields);
    }

    private static Column transformArrayField(
        Column column, ArrayType arrayType, int precision, int scale, Column currencyCodeColumn) {

        DataType elementType = arrayType.elementType();

        if (elementType.equals(DataTypes.DoubleType)) {
            return functions.transform(column, element -> transformDoubleField(element, precision, scale, currencyCodeColumn));
        } else if (elementType instanceof StructType) {
            return functions.transform(column, element -> transformNestedStruct(element, (StructType) elementType, precision, scale, currencyCodeColumn));
        }

        return column; // Return as-is for other types
    }
}
