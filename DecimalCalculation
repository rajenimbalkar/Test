import org.apache.spark.sql.*;
import org.apache.spark.sql.functions;
import org.apache.spark.sql.api.java.UDF1;
import org.apache.spark.sql.types.*;
import java.math.BigDecimal;
import java.util.*;
import java.util.stream.Collectors;

public class CurrencyDecimalConverter {

    public static void main(String[] args) {
        // Initialize Spark session
        SparkSession spark = SparkSession.builder()
                .appName("Currency Decimal Converter")
                .getOrCreate();

        // Register UDFs
        spark.udf().register("convertArrayField", new UDF1<List<Double>, List<BigDecimal>>() {
            @Override
            public List<BigDecimal> call(List<Double> values) throws Exception {
                if (values == null) return null;
                return values.stream()
                        .map(value -> value == null ? null : BigDecimal.valueOf(value).setScale(2, BigDecimal.ROUND_HALF_UP))
                        .collect(Collectors.toList());
            }
        }, DataTypes.createArrayType(DataTypes.createDecimalType(38, 2)));

        // Example dataset
        Dataset<Row> dataset = createSampleDataset(spark);

        // Specify the currency code field in the header (e.g., "currencyCodeField")
        String currencyCodeField = "currencyCode"; // Field name in header

        // Specify the enum class
        Class<? extends Enum<?>> enumClass = AccountFields.class;

        // Apply the method, passing the enum class and dataset
        Dataset<Row> updatedDataset = updateCurrencyDecimalPlaces(dataset, currencyCodeField, enumClass);

        // Show the results
        updatedDataset.show(false);
    }

    // Enum for account fields (can be extended)
    public enum AccountFields {
        F_ACCOUNT_BALANCE,
        F_ACCOUNT_DEPOSIT
    }

    // Method to process dataset rows
    public static Dataset<Row> updateCurrencyDecimalPlaces(Dataset<Row> dataset, String currencyCodeField, Class<? extends Enum<?>> enumClass) {
        // Extract enum field names dynamically
        Set<String> enumFieldNames = Stream.of(enumClass.getEnumConstants())
                                           .map(Enum::name)
                                           .collect(Collectors.toSet());

        // Add a temporary column for currency decimal places
        dataset = dataset.withColumn(
                "currencyDecimalPlaces",
                functions.udf((String currencyCode) -> getCurrencyDecimalPlaces(currencyCode), DataTypes.IntegerType)
                        .apply(functions.col(currencyCodeField))
        );

        // Process each row in the dataset
        StructType schema = dataset.schema();
        for (StructField field : schema.fields()) {
            String fieldName = field.name();
            DataType fieldType = field.dataType();

            if (fieldType instanceof StructType) {
                // Handle nested structs recursively
                dataset = updateNestedStruct(dataset, fieldName, enumFieldNames, currencyCodeField);
            } else if (fieldType instanceof ArrayType) {
                // Handle arrays of data
                dataset = dataset.withColumn(
                        fieldName,
                        functions.expr("transform(" + fieldName + ", x -> convertArrayField(x))")
                );
            } else if (fieldType == DataTypes.DoubleType) {
                // Check if the field matches enum and apply logic accordingly
                if (isEnumFieldNameMatching(fieldName, enumFieldNames)) {
                    dataset = dataset.withColumn(
                            fieldName,
                            functions.when(
                                    functions.col(fieldName).isNotNull(),
                                    functions.udf((Double value, Integer decimalPlaces) ->
                                                    convertToBigDecimalWithCurrency(value, decimalPlaces),
                                            DataTypes.createDecimalType(38, 2))  // Example precision/scale
                                    .apply(functions.col(fieldName), functions.col("currencyDecimalPlaces"))
                            ).otherwise(functions.col(fieldName))
                    );
                } else {
                    // Convert non-enum double fields to BigDecimal
                    dataset = dataset.withColumn(
                            fieldName,
                            functions.udf((Double value) ->
                                            convertToBigDecimal(value),
                                    DataTypes.createDecimalType(38, 2) // Example precision/scale
                            ).apply(functions.col(fieldName))
                    );
                }
            }
        }

        // Drop the temporary "currencyDecimalPlaces" column
        return dataset.drop("currencyDecimalPlaces");
    }

    // Method to handle arrays (same as previously mentioned)
    private static Dataset<Row> updateNestedStruct(Dataset<Row> dataset, String structFieldName, Set<String> enumFieldNames, String currencyCodeField) {
        // Handle logic for nested structs
        // You can call the `updateCurrencyDecimalPlaces` method here recursively if needed
        return dataset;
    }

    // Method to check enum field names
    private static boolean isEnumFieldNameMatching(String fieldName, Set<String> enumFieldNames) {
        // Handle field name comparison with enum fields (with or without F_ prefix)
        return enumFieldNames.contains(fieldName.replace("F_", ""));
    }

    // Get currency decimal places based on currency code
    private static int getCurrencyDecimalPlaces(String currencyCode) {
        try {
            return java.util.Currency.getInstance(currencyCode).getDefaultFractionDigits();
        } catch (IllegalArgumentException e) {
            return 2; // Default to 2 if currency is invalid
        }
    }

    // Convert to BigDecimal with currency-specific decimal places
    private static BigDecimal convertToBigDecimalWithCurrency(Double value, Integer decimalPlaces) {
        if (value == null || decimalPlaces == null) return null;
        return BigDecimal.valueOf(value).movePointLeft(decimalPlaces).setScale(decimalPlaces, BigDecimal.ROUND_HALF_UP);
    }

    // Convert to BigDecimal with default precision/scale
    private static BigDecimal convertToBigDecimal(Double value) {
        if (value == null) return null;
        return BigDecimal.valueOf(value).setScale(2, BigDecimal.ROUND_HALF_UP);
    }

    // Sample dataset for demonstration (replace this with your actual dataset)
    private static Dataset<Row> createSampleDataset(SparkSession spark) {
        // Sample data with account, trailer, and data rows
        List<Row> rows = Arrays.asList(
                RowFactory.create("USD", 123.00, 5000.55),
                RowFactory.create("EUR", 321.45, 1500.33)
        );

        // Define schema with header, data, and trailer
        StructType schema = new StructType(new StructField[]{
                new StructField("currencyCode", DataTypes.StringType, false, Metadata.empty()),
                new StructField("F_ACCOUNT_BALANCE", DataTypes.DoubleType, false, Metadata.empty()),
                new StructField("F_ACCOUNT_DEPOSIT", DataTypes.DoubleType, false, Metadata.empty())
        });

        // Create DataFrame from the sample data
        return spark.createDataFrame(rows, schema);
    }
}
