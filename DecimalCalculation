import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.Column;
import org.apache.spark.sql.functions;
import org.apache.spark.sql.types.*;

import java.util.Currency;

public class DistributedDatasetProcessor {

    public static Dataset<Row> processDataset(
        Dataset<Row> dataset, int precision, int scale, String currencyCodeField) {

        StructType schema = dataset.schema();
        return transformDataset(dataset, schema, precision, scale, currencyCodeField);
    }

    private static Dataset<Row> transformDataset(
        Dataset<Row> dataset, StructType schema, int precision, int scale, String currencyCodeField) {

        // Extract currencyCode from the header field and apply it to the entire row
        Column extractedCurrencyCode = functions.col("header." + currencyCodeField);

        for (StructField field : schema.fields()) {
            String fieldName = field.name();
            DataType fieldType = field.dataType();

            if (fieldType.equals(DataTypes.DoubleType)) {
                // Transform DoubleType fields
                dataset = dataset.withColumn(
                    fieldName,
                    transformDoubleField(functions.col(fieldName), precision, scale, extractedCurrencyCode)
                );
            } else if (fieldType instanceof StructType) {
                // Recursively transform StructType fields
                dataset = dataset.withColumn(
                    fieldName,
                    transformNestedStruct(functions.col(fieldName), (StructType) fieldType, precision, scale, extractedCurrencyCode)
                );
            } else if (fieldType instanceof ArrayType) {
                // Transform ArrayType fields
                dataset = dataset.withColumn(
                    fieldName,
                    transformArrayField(functions.col(fieldName), (ArrayType) fieldType, precision, scale, extractedCurrencyCode)
                );
            }
        }

        return dataset;
    }

    private static Column transformDoubleField(Column column, int precision, int scale, Column currencyCodeColumn) {
        // Use a Spark SQL UDF to fetch the decimal places dynamically from java.util.Currency
        Column fractionDigits = getCurrencyFractionDigitsUDF().apply(currencyCodeColumn);

        return functions.expr(
            "CAST(round(" + column + ", " + fractionDigits + ") AS DECIMAL(" + precision + ", " + scale + "))"
        );
    }

    private static Column transformNestedStruct(
        Column column, StructType structType, int precision, int scale, Column currencyCodeColumn) {

        Column[] transformedFields = new Column[structType.fields().length];

        for (int i = 0; i < structType.fields().length; i++) {
            StructField field = structType.fields()[i];
            String fieldName = field.name();
            DataType fieldType = field.dataType();

            if (fieldType.equals(DataTypes.DoubleType)) {
                transformedFields[i] = transformDoubleField(column.getField(fieldName), precision, scale, currencyCodeColumn).alias(fieldName);
            } else if (fieldType instanceof StructType) {
                transformedFields[i] = transformNestedStruct(column.getField(fieldName), (StructType) fieldType, precision, scale, currencyCodeColumn).alias(fieldName);
            } else if (fieldType instanceof ArrayType) {
                transformedFields[i] = transformArrayField(column.getField(fieldName), (ArrayType) fieldType, precision, scale, currencyCodeColumn).alias(fieldName);
            } else {
                transformedFields[i] = column.getField(fieldName);
            }
        }

        return functions.struct(transformedFields);
    }

    private static Column transformArrayField(
        Column column, ArrayType arrayType, int precision, int scale, Column currencyCodeColumn) {

        DataType elementType = arrayType.elementType();

        if (elementType.equals(DataTypes.DoubleType)) {
            return functions.transform(column, element -> transformDoubleField(element, precision, scale, currencyCodeColumn));
        } else if (elementType instanceof StructType) {
            return functions.transform(column, element -> transformNestedStruct(element, (StructType) elementType, precision, scale, currencyCodeColumn));
        }

        return column; // Return as-is for other types
    }

    private static org.apache.spark.sql.expressions.UserDefinedFunction getCurrencyFractionDigitsUDF() {
        return functions.udf(
            (String currencyCode) -> {
                if (currencyCode == null || currencyCode.isEmpty()) {
                    return 2; // Default to 2 decimal places if currency code is null or invalid
                }
                try {
                    Currency currency = Currency.getInstance(currencyCode);
                    return currency.getDefaultFractionDigits();
                } catch (IllegalArgumentException e) {
                    // Handle cases where the currency code is invalid
                    return 2; // Default to 2 decimal places for unknown currencies
                }
            },
            DataTypes.IntegerType
        );
    }
}
