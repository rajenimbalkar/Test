from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.jdbc.hooks.jdbc import JDBCHook
from airflow.providers.jdbc.operators.jdbc import JdbcOperator
from airflow.utils.dates import days_ago
from airflow.models import Variable
from airflow.utils.email import send_email
import logging

# Configurable variables from Airflow
purge_period_months = int(Variable.get("purge_period_months", default_var=13))
notification_email = Variable.get("notification_email")

# Tables to be purged
tables_to_purge = ["table1", "table2", "table3", "table4"]

default_args = {
    "owner": "airflow",
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
}

# SQL Template for deleting records older than the configured months
DELETE_SQL_TEMPLATE = """
DELETE FROM {table_name}
WHERE record_date < CURRENT DATE - {purge_period_months} MONTHS
"""

# Function to get count of deleted records using JdbcOperator
def delete_and_count_records(table_name, **kwargs):
    jdbc_hook = JDBCHook(jdbc_conn_id="your_db2_jdbc_connection_id")  # Set your DB2 connection ID here
    
    # Delete records and count rows affected
    delete_sql = DELETE_SQL_TEMPLATE.format(table_name=table_name, purge_period_months=purge_period_months)
    records_deleted = jdbc_hook.run(delete_sql)
    
    # Log the result
    logging.info(f"Deleted {records_deleted} records from {table_name}.")
    
    # Push the result to XCom for reporting in email
    return {"table_name": table_name, "deleted_count": records_deleted}

# Function to send email with the results of the purge
def send_report_email(ti, **kwargs):
    success_results = ti.xcom_pull(key="return_value", task_ids=[f"delete_{table}" for table in tables_to_purge])
    
    # Determine success or failure for each table
    failed_tables = [res["table_name"] for res in success_results if res is None]
    success_counts = {res["table_name"]: res["deleted_count"] for res in success_results if res is not None}

    # Construct email subject and body
    subject = "Purge DAG Report"
    if not failed_tables:
        body = f"Successfully deleted records older than {purge_period_months} months from all tables.\n\n"
        for table, count in success_counts.items():
            body += f"Table '{table}': {count} records deleted.\n"
    else:
        body = f"Failed to delete records from the following tables: {', '.join(failed_tables)}\n\n"
        for table, count in success_counts.items():
            body += f"Table '{table}': {count} records deleted.\n"
    
    # Send email
    send_email(to=notification_email, subject=subject, html_content=body)

# Define the DAG
with DAG(
    dag_id="purge_old_records_dag",
    default_args=default_args,
    schedule_interval="@monthly",
    start_date=days_ago(1),
    catchup=False,
) as dag:

    delete_tasks = []
    for table in tables_to_purge:
        delete_task = PythonOperator(
            task_id=f"delete_{table}",
            python_callable=delete_and_count_records,
            op_kwargs={"table_name": table},
            provide_context=True,
        )
        delete_tasks.append(delete_task)

    send_email_task = PythonOperator(
        task_id="send_report_email",
        python_callable=send_report_email,
        provide_context=True,
    )

    # Set task dependencies
    delete_tasks >> send_email_task
