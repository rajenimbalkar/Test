from airflow import DAG
from airflow.hooks.jdbc_hook import JdbcHook
from airflow.operators.python import PythonOperator
from airflow.providers.email.operators.email import EmailOperator
from airflow.models import Variable
from airflow.utils.dates import days_ago
import json
import logging

# DAG default arguments
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
}

# Define DAG
with DAG(
    'db2_purge_job_dag_with_jdbchook',
    default_args=default_args,
    description='Purge old records from DB2 tables using JdbcHook and optimized batch processing',
    schedule_interval='@daily',
    start_date=days_ago(1),
    catchup=False,
) as dag:

    # Email recipient
    email_recipient = Variable.get("email_recipient", default_var="dl@example.com")

    # Load purge configuration from Airflow Variable
    purge_config = json.loads(Variable.get("purge_config"))

    def batch_purge_with_jdbchook():
        """
        Perform batch purge using JdbcHook based on purge configuration.
        """
        jdbc_hook = JdbcHook(jdbc_conn_id='db2_default')
        purge_results = []

        for config in purge_config:
            table_name = config['table_name']
            date_column = config['date_column']
            purge_days = config['purge_days']
            batch_size = 1000  # Define a batch size

            # Generate SQL for batch delete
            sql = f"""
                DELETE FROM {table_name}
                WHERE {date_column} <= CURRENT DATE - {purge_days} DAYS
                FETCH FIRST {batch_size} ROWS ONLY;
            """

            records_deleted = 0
            total_deleted = 0

            # Execute delete in batches
            while True:
                try:
                    affected_rows = jdbc_hook.run(sql)
                    records_deleted += affected_rows
                    total_deleted += affected_rows
                    if affected_rows < batch_size:
                        break  # Exit when fewer than batch_size rows are deleted

                except Exception as e:
                    logging.error(f"Error deleting from {table_name}: {e}")
                    purge_results.append((table_name, config['type'], "Failed", str(e)))
                    break

            # Append result to the report
            purge_results.append((table_name, config['type'], total_deleted, "Success" if records_deleted else "Failed"))

        return purge_results

    def send_purge_report(**kwargs):
        """
        Generates and sends an HTML summary email report for the purge tasks.
        """
        purge_results = kwargs['ti'].xcom_pull(task_ids='batch_purge_task')

        html_template = """
        <html>
            <h2>Purge Job Summary Report</h2>
            <table border="1" cellpadding="5">
                <tr>
                    <th>Table Name</th>
                    <th>Type</th>
                    <th>Records Deleted</th>
                    <th>Status</th>
                </tr>
                {rows}
            </table>
        </html>
        """

        rows = ""
        for result in purge_results:
            table_name, purge_type, total_deleted, status = result
            rows += f"""
                <tr>
                    <td>{table_name}</td>
                    <td>{purge_type.capitalize()}</td>
                    <td>{total_deleted}</td>
                    <td>{status}</td>
                </tr>
            """

        email_content = html_template.format(rows=rows)

        email = EmailOperator(
            task_id='send_email_report',
            to=email_recipient,
            subject='DB2 Purge Job Report',
            html_content=email_content
        )
        email.execute(context=kwargs)

    # Task to execute the batch purge with JdbcHook
    batch_purge_task = PythonOperator(
        task_id='batch_purge_task',
        python_callable=batch_purge_with_jdbchook,
        provide_context=True,
    )

    # Task to send the report email after purging is complete
    send_email = PythonOperator(
        task_id='send_purge_report',
        python_callable=send_purge_report,
        provide_context=True,
    )

    # Task dependencies
    batch_purge_task >> send_email
