package com.example;

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.junit.AfterClass;
import org.junit.BeforeClass;
import org.junit.Test;

import java.io.File;
import java.io.IOException;
import org.apache.commons.io.FileUtils;

import static org.junit.Assert.assertEquals;

public class FileReaderTest {
    private static SparkSession spark;
    private static final String INPUT_PATH = "src/test/resources/input.csv";

    @BeforeClass
    public static void setUp() {
        spark = SparkSession.builder()
                .appName("JUnit Spark Test")
                .master("local[*]")
                .getOrCreate();

        // Create test input file
        File inputFile = new File(INPUT_PATH);
        try {
            FileUtils.writeStringToFile(inputFile, "a,b\n1,2\n3,4", "UTF-8");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @AfterClass
    public static void tearDown() {
        spark.stop();
        FileUtils.deleteQuietly(new File(INPUT_PATH));
    }

    @Test
    public void testFileReader() {
        FileReader fileReader = new FileReader(spark);
        Dataset<Row> df = fileReader.read(INPUT_PATH);
        assertEquals(2, df.count());
    }
}
