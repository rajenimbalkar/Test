To manage multiple validation files for different positional fixed-width file types in Java with Apache Spark, you can organize your validation rules into separate YAML files. This approach simplifies maintenance and scalability when supporting diverse file formats.

### Step-by-Step Implementation

1. **Define Separate YAML Validation Files**:

   Create individual YAML files for each file type with the respective validation rules.

   - **`validation_type1.yaml`**:
     ```yaml
     header:
       length: 50
       patterns:
         recordType:
           start: 0
           end: 3
           regex: "^HDR$"
         date:
           start: 4
           end: 12
           regex: "^[0-9]{8}$"
         onlyCharacters:
           start: 12
           end: 22
           regex: "^[A-Za-z]+$"
         onlyIntegers:
           start: 22
           end: 32
           regex: "^[0-9]+$"
     data:
       length: 100
       patterns:
         recordType:
           start: 0
           end: 3
           regex: "^DAT$"
         date:
           start: 20
           end: 28
           regex: "^[0-9]{8}$"
         onlyCharacters:
           start: 28
           end: 38
           regex: "^[A-Za-z]+$"
         onlyIntegers:
           start: 38
           end: 48
           regex: "^[0-9]+$"
     trailer:
       length: 50
       patterns:
         recordType:
           start: 0
           end: 3
           regex: "^TRL$"
         onlyCharacters:
           start: 4
           end: 14
           regex: "^[A-Za-z]+$"
         onlyIntegers:
           start: 14
           end: 24
           regex: "^[0-9]+$"
     ```

   - **`validation_type2.yaml`**:
     ```yaml
     header:
       length: 60
       patterns:
         recordType:
           start: 0
           end: 4
           regex: "^HDR2$"
         date:
           start: 5
           end: 13
           regex: "^[0-9]{8}$"
         onlyCharacters:
           start: 14
           end: 25
           regex: "^[A-Za-z]+$"
         onlyIntegers:
           start: 25
           end: 35
           regex: "^[0-9]+$"
     data:
       length: 120
       patterns:
         recordType:
           start: 0
           end: 4
           regex: "^DAT2$"
         date:
           start: 30
           end: 38
           regex: "^[0-9]{8}$"
         onlyCharacters:
           start: 40
           end: 50
           regex: "^[A-Za-z]+$"
         onlyIntegers:
           start: 50
           end: 60
           regex: "^[0-9]+$"
     trailer:
       length: 60
       patterns:
         recordType:
           start: 0
           end: 4
           regex: "^TRL2$"
         onlyCharacters:
           start: 5
           end: 15
           regex: "^[A-Za-z]+$"
         onlyIntegers:
           start: 15
           end: 25
           regex: "^[0-9]+$"
     ```

2. **Utility to Load Validation Config**:

   Create a utility to load the validation rules from the specified YAML file based on the file type.

   ```java
   import org.yaml.snakeyaml.Yaml;
   import java.io.InputStream;
   import java.util.Map;

   public class ValidationConfig {
       private Map<String, Map<String, Object>> validation;

       public ValidationConfig(Map<String, Map<String, Object>> validation) {
           this.validation = validation;
       }

       public static ValidationConfig load(String filePath) {
           Yaml yaml = new Yaml();
           try (InputStream inputStream = ValidationConfig.class.getClassLoader().getResourceAsStream(filePath)) {
               return new ValidationConfig(yaml.load(inputStream));
           } catch (Exception e) {
               throw new RuntimeException("Error loading validation configuration from " + filePath, e);
           }
       }

       public Map<String, Map<String, Object>> getValidation() {
           return validation;
       }
   }
   ```

3. **Modify `RecordValidator` to Support Multiple File Types**:

   Adjust the `RecordValidator` class to use validation rules loaded dynamically based on the file type.

   ```java
   import java.util.HashMap;
   import java.util.Map;
   import java.util.regex.Pattern;

   public class RecordValidator {
       private Map<String, Map<String, Object>> rules;

       public RecordValidator(Map<String, Map<String, Object>> rules) {
           this.rules = rules;
       }

       public Map<Integer, String> validateRecord(String record, String recordType, int lineNumber) {
           Map<Integer, String> errors = new HashMap<>();
           Map<String, Object> rule = rules.get(recordType);

           if (rule == null) {
               errors.put(lineNumber, "Unknown record type: " + recordType);
               return errors;
           }

           // Check length
           int expectedLength = (int) rule.get("length");
           if (record.length() != expectedLength) {
               errors.put(lineNumber, "Invalid length: expected " + expectedLength + ", got " + record.length());
           }

           // Validate patterns
           Map<String, Object> patterns = (Map<String, Object>) rule.get("patterns");
           patterns.forEach((key, value) -> {
               int start = (int) ((Map<String, Object>) value).get("start");
               int end = (int) ((Map<String, Object>) value).get("end");
               String regex = (String) ((Map<String, Object>) value).get("regex");
               String actualValue = record.substring(start, end).trim();

               if (!Pattern.matches(regex, actualValue)) {
                   errors.put(lineNumber, "Invalid " + key + " at positions " + start + "-" + end + ": expected pattern " + regex);
               }
           });

           return errors;
       }

       public void validateHeaderTrailerCounts(Map<String, Integer> headerTrailerCounts, Map<Integer, String> errors, int lineNumber) {
           headerTrailerCounts.forEach((type, count) -> {
               if (type.equals("HDR") && count != 1) {
                   errors.put(lineNumber, "Invalid header count: expected 1, got " + count);
               } else if (type.equals("TRL") && count != 1) {
                   errors.put(lineNumber, "Invalid trailer count: expected 1, got " + count);
               }
           });
       }
   }
   ```

4. **Main Spark Processing Logic**:

   Update the Spark application to dynamically select the validation configuration file based on the file type.

   ```java
   import org.apache.spark.sql.Dataset;
   import org.apache.spark.sql.Encoders;
   import org.apache.spark.sql.SparkSession;

   import java.util.HashMap;
   import java.util.List;
   import java.util.Map;
   import java.util.concurrent.atomic.AtomicInteger;

   public class FileValidator {
       public static void main(String[] args) {
           SparkSession spark = SparkSession.builder()
                   .appName("File Validator")
                   .master("local[*]")
                   .getOrCreate();

           // Determine the file type and load corresponding validation configuration
           String fileType = "type1"; // This would be determined dynamically, possibly from arguments or file metadata
           String validationFile = "validation_" + fileType + ".yaml";
           ValidationConfig config = ValidationConfig.load(validationFile);
           RecordValidator validator = new RecordValidator(config.getValidation());

           // Example datasets for different file types
           List<String> lines = fileType.equals("type1") ? List.of(
               "HDR20220101Header12345",  // Header
               "DAT20220101SomeData12345678",
               "TRLTrailer112233"  // Trailer
           ) : List.of(
               "HDR220220101Header   12345",  // Header
               "DAT220220101SomeData   12345678",
               "TRL2TrailerRecord 112233"  // Trailer
           );

           Dataset<String> dataset = spark.createDataset(lines, Encoders.STRING());

           // Process each row
           Map<String, Integer> headerTrailerCounts = new HashMap<>();
           AtomicInteger lineNumber = new AtomicInteger(1);
           Map<Integer, String> errorMap = new HashMap<>();

           dataset.foreach(row -> {
               String recordType = row.substring(0, 3).trim();
               Map<Integer, String> errors = validator.validateRecord(row, recordType, lineNumber.getAndIncrement());

               if (recordType.equals("HDR") || recordType.equals("HDR2")) {
                   headerTrailerCounts.put("HDR", headerTrailerCounts.getOrDefault("HDR", 0) + 1);
               } else if (recordType.equals("TRL") || recordType.equals("TRL2")) {
                   headerTrailerCounts.put("TRL", headerTrailerCounts.getOrDefault("TRL", 0) + 1);
               }

               if (!errors.isEmpty()) {
                   errorMap.putAll(errors);
               }
           });

           // Validate header and trailer counts per set
           validator.validateHeaderTrailerCounts(headerTrailerCounts, errorMap, -1);

           // Print and return error map
           errorMap.forEach
